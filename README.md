Zhao, Y., Pang, T., Du, C., Yang, X., Li, C., Cheung, N. M. M., & Lin, M. (2024). On evaluating adversarial robustness of large vision-language models. Advances in Neural Information Processing Systems, 36.<br>
https://github.com/yunqing-me/AttackVLM<br><br>
Li, C., Tian, Y., Zerong, Z., Song, Y., & Xia, F. (2024, August). Challenging Large Language Models with New Tasks: A Study on their Adaptability and Robustness. In Findings of the Association for Computational Linguistics ACL 2024 (pp. 8140-8162).<br>
https://github.com/CLINEEK/ELAGENT<br><br>
Chen, Z., Wang, Z., Yang, Y., Li, Q., & Zhang, Z. (2024). PID Control-Based Self-Healing to Improve the Robustness of Large Language Models. arXiv preprint arXiv:2404.00828.<br>
https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models<br><br>
Luo, W., Ma, S., Liu, X., Guo, X., & Xiao, C. (2024). Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks. arXiv preprint arXiv:2404.03027.<br>
https://github.com/IBM/EMNLP_2024_LLM_robustness/tree/master<br><br>
Huang, Z., Wang, X., Zhang, F., Xu, Z., Zhang, C., Zheng, X., & Huang, X. (2024). Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement. arXiv preprint arXiv:2407.01461.<br>
https://github.com/Huangzisu/query-refinement<br><br>
Zheng, J., Ritter, A., & Xu, W. (2024). NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms. arXiv preprint arXiv:2402.12261.<br>
https://github.com/JonathanQZheng/NEO-BENCH<br><br>
Jiang, M., Huang, T., Guo, B., Lu, Y., & Zhang, F. (2024). Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information. arXiv preprint arXiv:2408.10615.<br>
https://github.com/ymt9/GSMIR/tree/master<br><br>
Cong, T., Ran, D., Liu, Z., He, X., Liu, J., Gong, Y., ... & Wang, X. (2024). Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging. arXiv preprint arXiv:2404.05188.<br>
https://github.com/ThuCCSLab/MergeGuard<br><br>

Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., ... & Xie, X. (2024). A survey on evaluation of large language models. ACM Transactions on Intelligent Systems and Technology, 15(3), 1-45.<br>
https://github.com/lifan-yuan/OOD_NLP<br><br>
Yu, S. C. L., He, J., Minervini, P., & Pan, J. Z. (2024). Evaluating the Adversarial Robustness of Retrieval-Based In-Context Learning for Large Language Models. arXiv preprint arXiv:2405.15984.<br>
https://github.com/simonucl/adv-retreival-icl<br><br>
Zhang, Z., Guo, Y., Liang, Y., Zhao, D., & Duan, N. (2024). PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion. arXiv preprint arXiv:2403.03788.<br>
https://github.com/ZekaiGalaxy/PPTC-R<br><br>
Yuan, L., Chen, Y., Cui, G., Gao, H., Zou, F., Cheng, X., ... & Sun, M. (2023). Revisiting out-of-distribution robustness in nlp: Benchmarks, analysis, and LLMs evaluations. Advances in Neural Information Processing Systems, 36, 58478-58507.<br>
https://github.com/lifan-yuan/OOD_NLP<br><br>

